{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d0c6ab-fbce-4e3f-b36e-2df310557992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "import numpy.matlib as mb\n",
    "\n",
    "class TFIDF(object):\n",
    "\n",
    "    def __init__(self, corpus_title,appendix,corpus,title_grams = 3,appendix_grams = 2,corpus_grams = 1,title_weight = 10, appendix_weight = 5):        \n",
    "        self.corpus = corpus\n",
    "        self.corpus_title = corpus_title\n",
    "        self.corpus_appendix = appendix\n",
    "        \n",
    "\n",
    "        self.title_weight = title_weight\n",
    "        self.appendix_weight = appendix_weight\n",
    "        \n",
    "        self.title_vect = CountVectorizer(ngram_range=(1,title_grams))\n",
    "        self.appen_vect = CountVectorizer(ngram_range=(1,appendix_grams))        \n",
    "        self.corpus_vect = CountVectorizer(ngram_range=(1,corpus_grams)) \n",
    "        \n",
    "        self.norm_corpus  = None        \n",
    "        self.norm_corpus_title = None\n",
    "        self.norm_corpus_appendix = None\n",
    "    \n",
    "    \n",
    "    def __clean__(self,d):\n",
    "        #Removing Stop Words\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        d = re.sub(r'[^a-zA-Z0-9\\s]', '', str(d), re.I|re.A)\n",
    "        d = d.lower().strip()\n",
    "        tks = nltk.word_tokenize(d)\n",
    "        return(' '.join([t for t in tks if t not in stop_words]))\n",
    "        \n",
    "    def __normalize_corpus(self, title,appendix, corp):\n",
    "        corp = self.__clean__(corp)\n",
    "        title = self.__clean__(title)\n",
    "        appendix = self.__clean__(appendix)\n",
    "        \n",
    "        # Title ngrams\n",
    "        self.title_vect.fit([str(title)])\n",
    "        titletrigrams = self.title_vect.get_feature_names() \n",
    "        \n",
    "        # Appenidx ngrams\n",
    "        self.appen_vect.fit([str(appendix)])\n",
    "        apptrigrams = self.appen_vect.get_feature_names() \n",
    "        \n",
    "        # Corpus ngrams\n",
    "        self.corpus_vect.fit([str(corp)])\n",
    "        corptrigrams = self.corpus_vect.get_feature_names()\n",
    "        \n",
    "   \n",
    "        return ('|'.join(titletrigrams),'|'.join(apptrigrams),'|'.join(corptrigrams))\n",
    "\n",
    "###### Vector Functions\n",
    "    def preprocessing_text(self):\n",
    "        n_c = np.vectorize(self.__normalize_corpus)\n",
    "        self.norm_corpus_title,self.norm_corpus_appendix,self.norm_corpus = n_c(self.corpus_title,self.corpus_appendix,self.corpus)\n",
    "        del(self.corpus_title,self.corpus_appendix,self.corpus)\n",
    "\n",
    "    def build_corp_vect(self,title,appendix,corp):   \n",
    "        document = title + '|' + appendix + '|'+ corp\n",
    "        words = document.split('|')\n",
    "        # words = np.lib.pad(words, ((0,self.N-len(words))), 'constant', constant_values= '')\n",
    "        words = np.array(words,dtype= object)\n",
    "        return(words)\n",
    "    \n",
    "    def n_tf_builder(self,title,appendix,corp):\n",
    "        doc_words = corp.split('|')\n",
    "        title_words = title.split('|')\n",
    "        appendix_words = appendix.split('|')\n",
    "        bowf_doc = Counter({w:1 for w in doc_words})\n",
    "        bowf_doc.update({w:self.title_weight for w in title_words})\n",
    "        bowf_doc.update({w:self.appendix_weight for w in appendix_words})\n",
    "        bowf_doc.update(self.features_dict)\n",
    "        return(bowf_doc)\n",
    "######\n",
    "\n",
    "    def build_corpus(self):\n",
    "        #Corpus\n",
    "        corp_vect = np.vectorize(self.build_corp_vect)\n",
    "        corpus_words_array = corp_vect(self.norm_corpus_title,self.norm_corpus_appendix,self.norm_corpus)\n",
    "        corpus_words = list(set(np.concatenate(corpus_words_array,axis =0)))\n",
    "        features_dict = {w:0 for w in corpus_words}\n",
    "        self.features_dict = features_dict\n",
    "        # self.tf = pd.DataFrame([],columns = dict(sorted(self.features_dict.items(),key= lambda x:x[0])).keys())\n",
    "        \n",
    "    def cal_tf(self):\n",
    "        self.build_corpus()\n",
    "        tf_vect = np.vectorize(self.n_tf_builder)\n",
    "        tf = tf_vect(self.norm_corpus_title,self.norm_corpus_appendix,self.norm_corpus)\n",
    "        self.tf = pd.DataFrame(list(tf),columns = sorted(self.features_dict.keys()))\n",
    "        \n",
    "    def cal_df(self):\n",
    "        features_names = list(self.tf.columns)\n",
    "        df = np.diff(sp.csc_matrix(self.tf, copy=True).indptr)\n",
    "        df = 1 + df\n",
    "        self.df = df\n",
    "        \n",
    "    def cal_idf(self):\n",
    "        N = 1 + len(self.norm_corpus)\n",
    "        idf = (1.0 + np.log(float(N) / self.df)) \n",
    "        idf_d = sp.spdiags(idf, diags= 0, m=len(df), n= len(df)).todense()\n",
    "        del(self.df)\n",
    "        self.idf = idf\n",
    "#         self.idf_d = idf_d\n",
    "\n",
    "    def get_tfidf(self):\n",
    "        self.cal_tf()\n",
    "        self.cal_df()\n",
    "        self.cal_idf()\n",
    "        tf = np.array(self.tf, dtype='float64')\n",
    "        tfidf = tf * self.idf\n",
    "        norms = norm(tfidf , axis=1)\n",
    "        self.tfidf = pd.DataFrame(tfidf / norms[:,None],columns=self.tf.columns)\n",
    "        return (self.tfidf)\n",
    "    \n",
    "    \n",
    "    def vectorize(self,query):\n",
    "        vect = CountVectorizer(ngram_range=(1,3))\n",
    "        vect.fit(query)\n",
    "        vect = Counter({w:1 for w in vect.get_feature_names() if w in self.features_dict.keys()})\n",
    "        vect.update(self.features_dict)\n",
    "        return(np.array(list(({k:vect[k] for k in sorted(vect.keys())}).values()),dtype = 'float64'))\n",
    "    \n",
    "    def similarity(self,query_vector,tf_idf):\n",
    "        query_matrix = mb.repmat(query_vector,tf_idf.shape[0],1)\n",
    "        scores = np.sum(tf_idf*query_matrix,axis =1)/(np.linalg.norm(tf_idf,axis=1)/np.linalg.norm(query_matrix,axis=1))\n",
    "        similar_scores = {i: score for i,score in enumerate(list(scores))}\n",
    "        similar_scores = sorted(similar_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return(similar_scores)\n",
    "    \n",
    "    def update(self,New_Title,New_Appendix,New_Corpus):\n",
    "        n_c = np.vectorize(self.__normalize_corpus)\n",
    "        self.New_Title,self.New_Appendix,self.New_Corpus = n_c(New_Title,New_Appendix,New_Corpus)\n",
    "        \n",
    "        # Corpus\n",
    "        corp_vect = np.vectorize(self.build_corp_vect)\n",
    "        corpus_words_array = corp_vect(self.New_Title,self.New_Appendix,self.New_Corpus)\n",
    "        corpus_words = list(set(np.concatenate(corpus_words_array,axis =0)))\n",
    "        original_corpus = list(self.features_dict.keys())\n",
    "        new_words = [w for w in corpus_words if w not in original_corpus]\n",
    "        new_full_corpus = new_words + original_corpus\n",
    "        self.features_dict = {w:0 for w in new_full_corpus}\n",
    "        # Update_Files\n",
    "        self.norm_corpus_title = list(self.norm_corpus_title) + list(self.New_Title)\n",
    "        self.norm_corpus_appendix =  list(self.norm_corpus_appendix) + list(self.New_Appendix)\n",
    "        self.norm_corpus = list(self.norm_corpus) + list(self.New_Corpus)\n",
    "        \n",
    "        \n",
    "        tf_vect = np.vectorize(self.n_tf_builder)\n",
    "        tf = tf_vect(self.norm_corpus_title,self.norm_corpus_appendix,self.norm_corpus)\n",
    "        self.tf = pd.DataFrame(list(tf),columns = sorted(self.features_dict.keys()))\n",
    "        \n",
    "        self.cal_df()\n",
    "        self.cal_idf()\n",
    "        tf = np.array(self.tf, dtype='float64')\n",
    "        tfidf = tf * self.idf\n",
    "        norms = norm(tfidf , axis=1)\n",
    "        self.tfidf = pd.DataFrame(tfidf / norms[:,None],columns=self.tf.columns)\n",
    "        return (self.tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68330030-47f1-4924-b26f-3c84fab5dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tfidf_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40471cb5-7682-488a-854a-723aff3580f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 7)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "553a50ac-3a17-4328-a76a-603d3cb05f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_course_names = pd.read_csv('CourseNames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "768702d6-0369-4c29-bd5e-684b57bfc1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Course Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ABMO72 ABC Modeling Using SAS Activity Based M...</td>\n",
       "      <td>ABMO72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AML62OV SAS Anti Money Laundering Solution Ori...</td>\n",
       "      <td>AML62OV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ATEVA74C SAS Visual Analytics 7 4 An Introduct...</td>\n",
       "      <td>ATEVA74C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BNGDM17 Analytics Driven Forecasting</td>\n",
       "      <td>BNGDM17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BQBD14 Quality by Design QbD Using JMP Software</td>\n",
       "      <td>BQBD14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>YBUFTV2 SAS Business Intelligence Reporting Fa...</td>\n",
       "      <td>YBUFTV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>YOLPM2 Designing Tuning and Maintaining SAS OL...</td>\n",
       "      <td>YOLPM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>YVA283ES SAS Visual Analytics 1 para SAS Viya</td>\n",
       "      <td>YVA283ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>YVAE73 Exploring Data with SAS Visual Analytics</td>\n",
       "      <td>YVAE73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>YVAFT73 SAS Visual Analytics Fast Track</td>\n",
       "      <td>YVAFT73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               Name Course Code\n",
       "0             0  ABMO72 ABC Modeling Using SAS Activity Based M...      ABMO72\n",
       "1             1  AML62OV SAS Anti Money Laundering Solution Ori...     AML62OV\n",
       "2             2  ATEVA74C SAS Visual Analytics 7 4 An Introduct...    ATEVA74C\n",
       "3             3             BNGDM17 Analytics Driven Forecasting       BNGDM17\n",
       "4             4  BQBD14 Quality by Design QbD Using JMP Software        BQBD14\n",
       "..          ...                                                ...         ...\n",
       "336         336  YBUFTV2 SAS Business Intelligence Reporting Fa...     YBUFTV2\n",
       "337         337  YOLPM2 Designing Tuning and Maintaining SAS OL...      YOLPM2\n",
       "338         338    YVA283ES SAS Visual Analytics 1 para SAS Viya      YVA283ES\n",
       "339         339  YVAE73 Exploring Data with SAS Visual Analytics        YVAE73\n",
       "340         340          YVAFT73 SAS Visual Analytics Fast Track       YVAFT73\n",
       "\n",
       "[341 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79918938-432c-4993-938f-9aab6cf8b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer = TFIDF(df['Title'],df['Appendix'],df['text'])\n",
    "Vectorizer.preprocessing_text()\n",
    "tf_idf = Vectorizer.get_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c901bd6e-c80e-49e8-9783-b1ec648dc0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 116918)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "54760c9d-65c0-4278-bf3b-c4c1c29a0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.to_pickle(\"./tfidf_Complete.pkl\")\n",
    "\n",
    "import json\n",
    "with open('tfidf_Complete.txt', 'w') as file:\n",
    "    json.dump(Vectorizer.features_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "11b527c6-3c3d-4d88-8a72-13cdf6132c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: ARIMA\n",
      "Finding Document Using Cosine Similarity: \n",
      "BNGDM17\n",
      "1 : analytics driven forecasting\n",
      "Cosine Similarity: 0.056280599590098214\n",
      "-----------------------------------------------\n",
      "LWSTSM51\n",
      "2 : time series modeling essentials\n",
      "Cosine Similarity: 0.054718778512563564\n",
      "-----------------------------------------------\n",
      "LWFETS42\n",
      "3 : forecasting sas software programming approach\n",
      "Cosine Similarity: 0.05026134736707092\n",
      "-----------------------------------------------\n",
      "LWAPIT62\n",
      "4 : sas asset performance analytics industrial application internet things\n",
      "Cosine Similarity: 0.04878558417982272\n",
      "-----------------------------------------------\n",
      "LWFSP42\n",
      "5 : sas forecast server procedures\n",
      "Cosine Similarity: 0.0425406073914485\n",
      "-----------------------------------------------\n",
      "LWHPF123\n",
      "6 : sas high performance forecasting software\n",
      "Cosine Similarity: 0.042125095511869035\n",
      "-----------------------------------------------\n",
      "LWCDS01\n",
      "7 : science statistical methods\n",
      "Cosine Similarity: 0.011711534791555026\n",
      "-----------------------------------------------\n",
      "LWYVAT01\n",
      "8 : sas visual analytics transitioning sas sas viya\n",
      "Cosine Similarity: 0.011435628704782154\n",
      "-----------------------------------------------\n",
      "LWROSI01\n",
      "9 : sas viya integration machine learning\n",
      "Cosine Similarity: 0.011101404383040338\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_similar_articles(q, df_):\n",
    "  print(\"topic:\", q)\n",
    "  print(\"Finding Document Using Cosine Similarity: \")\n",
    "  # Convert the query become a vector\n",
    "  q_vec = Vectorizer.vectorize([q])\n",
    "  # print(q_vec)\n",
    "  sim_sorted = Vectorizer.similarity(q_vec,df_)\n",
    "  # Print the articles and their similarity values\n",
    "  # print(sim_sorted)\n",
    "  i = 1\n",
    "  for k, v in sim_sorted:\n",
    "    if v != 0:\n",
    "        try:\n",
    "#             print(df.iloc[k,1].replace('.txt',''))\n",
    "#             print(v)\n",
    "            print(df.iloc[k,0].replace('.txt',''))\n",
    "            # print(str(i) + ' : ' + str(list(df_course_names[df_course_names['Course Code'] == (df.iloc[k,0].replace('.txt',''))]['Course Code'])[0]))\n",
    "            print(str(i) + ' : ' + str((df.iloc[k,:]['Title'])))\n",
    "            print(\"Cosine Similarity:\", v)\n",
    "            print('-----------------------------------------------')\n",
    "            i = i+1\n",
    "            if i == 10:\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "#       print(list_of_doc[k])\n",
    "#       print()\n",
    "  return(q_vec)\n",
    "\n",
    "\n",
    "# Add The Query\n",
    "q1 = ''\n",
    "# Call the function\n",
    "temp = get_similar_articles(q1, tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f91a27-556f-4046-a681-22c4786c8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pd.read_pickle(\"./tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f35f48-765b-4a04-904b-54a47bc0a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adv_analytics = pd.read_excel(\"Adv Analytics.xlsx\",sheet_name = 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995f8f79-5679-43f9-aed9-392dbc0f6e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Code</th>\n",
       "      <th>Level</th>\n",
       "      <th>Main Category Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNGDM17</td>\n",
       "      <td>3 Intermediate</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQBD14</td>\n",
       "      <td>2 Fundamental</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BSPV14</td>\n",
       "      <td>2 Fundamental</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAAVD83</td>\n",
       "      <td>4 Expert</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAAVS83</td>\n",
       "      <td>3 Intermediate</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>RECL2</td>\n",
       "      <td>3 Intermediate</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>RFW22</td>\n",
       "      <td>3 Intermediate</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SCA41</td>\n",
       "      <td>3 Intermediate</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>SSIMDE42</td>\n",
       "      <td>1 Beginner</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>SXASTS14</td>\n",
       "      <td>3 Intermediate</td>\n",
       "      <td>Advanced Analytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Course Code           Level Main Category Final\n",
       "0       BNGDM17  3 Intermediate  Advanced Analytics\n",
       "1        BQBD14   2 Fundamental  Advanced Analytics\n",
       "2        BSPV14   2 Fundamental  Advanced Analytics\n",
       "3       CAAVD83        4 Expert  Advanced Analytics\n",
       "4       CAAVS83  3 Intermediate  Advanced Analytics\n",
       "..          ...             ...                 ...\n",
       "122       RECL2  3 Intermediate  Advanced Analytics\n",
       "123       RFW22  3 Intermediate  Advanced Analytics\n",
       "124       SCA41  3 Intermediate  Advanced Analytics\n",
       "125    SSIMDE42      1 Beginner  Advanced Analytics\n",
       "126    SXASTS14  3 Intermediate  Advanced Analytics\n",
       "\n",
       "[127 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adv_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538c034b-d8f8-4256-a457-78972b5d548c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3 Intermediate    67\n",
       "4 Expert          43\n",
       "2 Fundamental     15\n",
       "1 Beginner         2\n",
       "Name: Level, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adv_analytics['Level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b81ac66-65b5-4df9-9ae1-9949ebeb43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc(text):\n",
    "    return(text.split('.')[0])\n",
    "\n",
    "def levels(text):\n",
    "    return(text.split()[0])\n",
    "\n",
    "df['Course Code'] = df['file_name'].apply(cc)\n",
    "\n",
    "Adv_analytics = pd.merge(df,Adv_analytics,on = 'Course Code',how = 'inner')\n",
    "Adv_analytics['Level'] = Adv_analytics['Level'].apply(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ee5247-281d-4fe0-b20d-5afe7e8fda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adv_Beg = Adv_analytics[(Adv_analytics['Level'] == '1') | (Adv_analytics['Level'] == '2')]\n",
    "\n",
    "Vectorizer_beg = TFIDF(Adv_Beg['Title'],Adv_Beg['Appendix'],Adv_Beg['text'],corpus_grams = 2)\n",
    "Vectorizer_beg.preprocessing_text()\n",
    "tf_idf = Vectorizer_beg.get_tfidf()\n",
    "import os\n",
    "os.chdir('./')\n",
    "os.mkdir('Adv_Beg')\n",
    "os.chdir('./Adv_Beg')\n",
    "tf_idf.to_pickle(\"./tfidf_Adv_Beg.pkl\")\n",
    "import json\n",
    "with open('tfidf_Adv_Beg.txt', 'w') as file:\n",
    "    json.dump(Vectorizer_beg.features_dict, file)\n",
    "Adv_Beg.to_csv('Adv_Beg.csv')\n",
    "os.chdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebf4b49-8003-441e-911d-a2b22131b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adv_Int = Adv_analytics[(Adv_analytics['Level'] == '3')]\n",
    "\n",
    "Vectorizer_Int = TFIDF(Adv_Int['Title'],Adv_Int['Appendix'],Adv_Int['text'],corpus_grams = 2)\n",
    "Vectorizer_Int.preprocessing_text()\n",
    "tf_idf = Vectorizer_Int.get_tfidf()\n",
    "os.chdir('./')\n",
    "os.mkdir('Adv_Int')\n",
    "os.chdir('./Adv_Int')\n",
    "tf_idf.to_pickle(\"./tfidf_Adv_Int.pkl\")\n",
    "with open('tfidf_Adv_Int.txt', 'w') as file:\n",
    "    json.dump(Vectorizer_Int.features_dict, file)\n",
    "Adv_Int.to_csv('Adv_Int.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd759d3e-67ad-4ae2-b2ec-f618bae6ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adv_Exp = Adv_analytics[(Adv_analytics['Level'] == '4')]\n",
    "\n",
    "Vectorizer_Exp = TFIDF(Adv_Exp['Title'],Adv_Exp['Appendix'],Adv_Exp['text'],corpus_grams = 2)\n",
    "Vectorizer_Exp.preprocessing_text()\n",
    "tf_idf = Vectorizer_Exp.get_tfidf()\n",
    "os.chdir('./')\n",
    "os.mkdir('Adv_Exp')\n",
    "os.chdir('./Adv_Exp')\n",
    "tf_idf.to_pickle(\"./tfidf_Adv_Exp.pkl\")\n",
    "with open('tfidf_Adv_Exp.txt', 'w') as file:\n",
    "    json.dump(Vectorizer_Exp.features_dict, file)\n",
    "Adv_Exp.to_csv('Adv_Exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b894e5a-59d4-46b2-beda-b437cb1cd68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer_Adv = TFIDF(Adv_analytics['Title'],Adv_analytics['Appendix'],Adv_analytics['text'],corpus_grams = 1)\n",
    "Vectorizer_Adv.preprocessing_text()\n",
    "tf_idf = Vectorizer_Adv.get_tfidf()\n",
    "os.chdir('./')\n",
    "os.mkdir('Adv_analytics')\n",
    "os.chdir('./Adv_analytics')\n",
    "tf_idf.to_pickle(\"./tfidf_Adv_analytics.pkl\")\n",
    "with open('tfidf_Adv_analytics.txt', 'w') as file:\n",
    "    json.dump(Vectorizer_Adv.features_dict, file)\n",
    "Adv_analytics.to_csv('Adv_analytics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "316840fe-0be1-4cd0-8a6f-a5dad3c85bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: regression\n",
      "Finding Document Using Cosine Similarity: \n",
      "CUJCOR2\n",
      "1 : statistics anova regression logistic regression fedex test\n",
      "Cosine Similarity: 0.14557379013918845\n",
      "-----------------------------------------------\n",
      "CDSV74\n",
      "2 : statistics anova regression logistic regression\n",
      "Cosine Similarity: 0.04141493184725628\n",
      "-----------------------------------------------\n",
      "BSPV14\n",
      "3 : manipulation analytics sas university edition\n",
      "Cosine Similarity: 0.023388435643858164\n",
      "-----------------------------------------------\n",
      "CAAVS83\n",
      "4 : programming sas iml software\n",
      "Cosine Similarity: 0.020515299599448283\n",
      "-----------------------------------------------\n",
      "ABMO72\n",
      "5 : quality design qbd jmp software\n",
      "Cosine Similarity: 0.019907920051878004\n",
      "-----------------------------------------------\n",
      "AML62OV\n",
      "6 : statistics fda process validation jmp software\n",
      "Cosine Similarity: 0.017573487774663537\n",
      "-----------------------------------------------\n",
      "BNGDM17\n",
      "7 : science business user\n",
      "Cosine Similarity: 0.014028647581237614\n",
      "-----------------------------------------------\n",
      "CSDI7\n",
      "8 : hands workshop end end modeling machine learning sas viya learners\n",
      "Cosine Similarity: 0.0062695404267880984\n",
      "-----------------------------------------------\n",
      "CAAVD83\n",
      "9 : forecasting model studio sas viya\n",
      "Cosine Similarity: 0.004151391557384964\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_similar_articles(q, df_):\n",
    "  print(\"topic:\", q)\n",
    "  print(\"Finding Document Using Cosine Similarity: \")\n",
    "  # Convert the query become a vector\n",
    "  q_vec = Vectorizer_beg.vectorize([q])\n",
    "  # print(q_vec)\n",
    "  sim_sorted = Vectorizer_beg.similarity(q_vec,df_)\n",
    "  # Print the articles and their similarity values\n",
    "  # print(sim_sorted)\n",
    "  i = 1\n",
    "  for k, v in sim_sorted:\n",
    "    if v != 0:\n",
    "        try:\n",
    "#             print(df.iloc[k,1].replace('.txt',''))\n",
    "#             print(v)\n",
    "            print(df.iloc[k,0].replace('.txt',''))\n",
    "            # print(str(i) + ' : ' + str(list(df_course_names[df_course_names['Course Code'] == (df.iloc[k,0].replace('.txt',''))]['Course Code'])[0]))\n",
    "            print(str(i) + ' : ' + str((Adv_Beg.iloc[k,:]['Title'])))\n",
    "            print(\"Cosine Similarity:\", v)\n",
    "            print('-----------------------------------------------')\n",
    "            i = i+1\n",
    "            if i == 10:\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "#       print(list_of_doc[k])\n",
    "#       print()\n",
    "  return(q_vec)\n",
    "\n",
    "\n",
    "# Add The Query\n",
    "q1 = 'regression'\n",
    "# Call the function\n",
    "temp = get_similar_articles(q1, tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5610f5-22c4-455e-8533-f787fe6c39aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
